{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Library Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Import**<br/>\n",
    "1) model1: estimate the concentration of any gas <br/>\n",
    "2) model2: estimate the concentration but gas feature is supplied <br/>\n",
    "3) model3: estimate the concentration but model is create for each particular gas <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data \n",
    "path = r\"C:\\Users\\BrechtDewilde\\Documents\\Github\\BDProject\\data\\data.csv\"\n",
    "data = pd.read_csv(path, index_col = 0)\n",
    "\n",
    "# Create a particular x, y dataset for each task\n",
    "data1 = data.iloc[:, 2:]\n",
    "data2 = pd.get_dummies(data.iloc[:, 1:])\n",
    "\n",
    "# for task 3 we need to create a model for each gas\n",
    "ethanol = data.loc[data['gas'] == \"Ethanol\"].iloc[:, 2:]\n",
    "ethylene = data.loc[data['gas'] == \"Ethylene\"].iloc[:, 2:]\n",
    "ammonia = data.loc[data['gas'] == \"Ammonia\"].iloc[:, 2:]\n",
    "acetaldehyde = data.loc[data['gas'] == \"Acetaldehyde\"].iloc[:, 2:]\n",
    "acetone = data.loc[data['gas'] == \"Acetone\"].iloc[:, 2:]\n",
    "toluene = data.loc[data['gas'] == \"Toluene\"].iloc[:, 2:]\n",
    "data3 = [ethanol, ethylene, ammonia, acetaldehyde, acetone, toluene]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-Test set split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1x_train, data1x_test, data1y_train, data1y_test = train_test_split(data1.iloc[:,1:], data1[\"concentration\"], random_state=0)\n",
    "data2x_train, data2x_test, data2y_train, data2y_test = train_test_split(data2.iloc[:,1:], data1[\"concentration\"], random_state=0)\n",
    "\n",
    "ethanol = {\"xtrain\": [], \"xtest\": [], \"ytrain\": [], \"ytest\": []} \n",
    "ethylene = {\"xtrain\": [], \"xtest\": [], \"ytrain\": [], \"ytest\": []} \n",
    "ammonia = {\"xtrain\": [], \"xtest\": [], \"ytrain\": [], \"ytest\": []} \n",
    "acetaldehyde = {\"xtrain\": [], \"xtest\": [], \"ytrain\": [], \"ytest\": []}\n",
    "acetone = {\"xtrain\": [], \"xtest\": [], \"ytrain\": [], \"ytest\": []} \n",
    "toluene = {\"xtrain\": [], \"xtest\": [], \"ytrain\": [], \"ytest\": []} \n",
    "\n",
    "data3_splitted = [ethanol, ethylene, ammonia, acetaldehyde, acetone, toluene]\n",
    "for index, df in enumerate(data3):\n",
    "    data3_splitted[index][\"xtrain\"], data3_splitted[index][\"xtest\"], data3_splitted[index][\"ytrain\"], data3_splitted[index][\"ytest\"] = train_test_split(df.iloc[:,1:], df[\"concentration\"], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization of the different prediction models**<br/>\n",
    "1) Elastic Net Regression <br/>\n",
    "2) Support Vector Regression <br/>\n",
    "3) Nearest Neighbour Regression<br/>\n",
    "4) Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = ElasticNetCV(cv=5, max_iter=10000, random_state=0)\n",
    "knn = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model fitting and Model evaluation** <br/>\n",
    "metrics: MSE, MAE and R2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the metric lists\n",
    "en_mse = []\n",
    "en_mae = []\n",
    "en_r = []\n",
    "\n",
    "# ElasticNet \n",
    "# Data 1 \n",
    "en.fit(data1x_train, data1y_train)\n",
    "en_mse.append(metrics.mean_squared_error(data1y_test, en.predict(data1x_test)))\n",
    "en_mae.append(metrics.mean_absolute_error(data1y_test, en.predict(data1x_test)))\n",
    "en_ar.append(metrics.r2_score(data1y_test, en.predict(data1x_test)))\n",
    "\n",
    "# Data 2 \n",
    "en.fit(data2x_train, data2y_train)\n",
    "en_mse.append(metrics.mean_squared_error(data2y_test, en.predict(data2x_test)))\n",
    "en_mae.append(metrics.mean_absolute_error(data2y_test, en.predict(data2x_test)))\n",
    "en_ar.append(metrics.r2_score(data2y_test, en.predict(data2x_test)))\n",
    "\n",
    "# Data 3\n",
    "for df in data3_splitted:\n",
    "    en.fit(df[\"xtrain\"], df[\"ytrain\"])\n",
    "    en_mse.append(metrics.mean_squared_error(df[\"ytest\"], en.predict(df[\"xtest\"])))\n",
    "    en_mae.append(metrics.mean_absolute_error(df[\"ytest\"], en.predict(df[\"xtest\"])))\n",
    "    en_ar.append(metrics.r2_score(df[\"ytest\"], en.predict(df[\"xtest\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mse = []\n",
    "params = {\"n_neighbors\": np.arange(1,5), \"weights\": [\"uniform\", \"distance\"]}\n",
    "grid = GridSearchCV(estimator=knn, param_grid=params,  scoring = \"neg_mean_squared_error\", cv = 5, iid = False)\n",
    "\n",
    "# Nearest\n",
    "# Data 1\n",
    "grid.fit(data1x_train, data1y_train)\n",
    "knn_mse.append(metrics.mean_squared_error(data1y_test, grid.predict(data1x_test)))\n",
    "\n",
    "# Data 2\n",
    "grid.fit(data2x_train, data2y_train)\n",
    "knn_mse.append(metrics.mean_squared_error(data2y_test, grid.predict(data2x_test)))\n",
    "\n",
    "# Data 3\n",
    "for df in data3_splitted:\n",
    "    grid.fit(df[\"xtrain\"], df[\"ytrain\"])\n",
    "    knn_mse.append(metrics.mean_squared_error(df[\"ytest\"], grid.predict(df[\"xtest\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = pd.DataFrame({\"Elastic Net\": en_mse, \"SVM\": [], \"NN\": [], \"Booster\": []})\n",
    "# mse_table.set_index([\"Data1\", \"Data2\", \"Ethanol\", \"Ethylene\", \"Ammonia\", \"Acetaldehyde\", \"Acetone\", \"Toluene\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'brier_score_loss',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr.fit(data1x_train, data1y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
